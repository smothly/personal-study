# CH2_이 책에서 다루는 도구와 데이터

---

## CH2-1 시스템

- PostgreSQL
  - 오픈소스 RDB
  - 이 책에서 기본적으로 사용(ver 9.6,10.2)
- Apache Hive
  - RDB에서 디스크 I/O가 주로 보틀넥이 됨
  - 보틀넥을 해결하기 위해 분산 파일 시스템이 고안됨
  - Hive는 HDFS위의 데이터를 SQL스러운 인터페이스로 처리해주는 시스템
  - 분산 파일 시스템의 순서를 맞추는 방법으로는 **MapReduce** 알고리즘이 고안
  - HDFS + MapReduce 아키텍처 = 초기의 Hadoop
  - **HiveQL**을 통해 쿼리를 자동으로 MR잡으로 전환하여 병렬 분산처리가 됨
  - 특징
    - **파일시스템 기반**
      - 특정 레코드의 변경 제거 어려움
      - 인덱스 디폴트로 없음
    - Hive는 HDFS에 저장되어 있는 데이터에 필요할 때 동적으로 스키마를 정의할 수 있음
    - UDF 활용 가능
    - 응답시간이 중요한 데이터는 적합하지 않음. throughput을 높일 때 유용
      - 응답시간이 늦은이유는 sql을 jar로 바꾸고 jar를 연산 노드에 배치하여 결과 얻는데 시간이 오래 걸림
      - 데이터 형식을 최적화 하거나 spark를 사용하여 응답시간을 줄이는 방법도 많이 쓰임
- Amazon Redshift
  - AWS 분산 병렬 RDB
  - postgreSQL과 호환성 가짐
  - 특징
    - RDB에서 다룰 수 없는 대량의 데이터와 상호 작용하는 쿼리를 실행할 때 효과적
    - 클라우드의 탄력성
    - 단점은 비용과 성능 튜닝의 어려움
    - postgesSQL과 달리 컬럼 기반 스토리지 사용
      - 레코드 별로 저장이 아니라 컬럼별로 저장하는 아키텍처
      - 데이터의 압축률 증가하여 디스크 I/O를 줄임
      - 필요한 컬럼만 추출하는 것이 좋음
- Google Bigquery
  - 데이터 노드 관리가 필요 없고, 읽어 들인 데이터 양에 따른 비용
  - 데이터가 적으면 적은 비용으로 운용 가능
  - google analytics나 구글 클라우드 서비스와 연동 가능
  - 특징
    - 레거시 SQL과 스탠다드 SQL 두 종류가 있음
    - 2016년 부터는 표준 SQL을 지원하기 시작함
    - 단점은 사용 요금을 예측하기 어려움
    - 자주 읽는 데이터를 따로 테이블로 빼거나 필요한 컬럼만 추출하는 테크닉이 필요
    - Redshift와 같은 컬럼 지향 스토리지
- Spark SQL
  - MR을 활용한 분산 처리 프레임워크인 Apach Spark의 기능 중 하나
  - 특징
    - 빅데이터의 활용과 관련된 대부분의 처리를 한꺼번에 구현 가능
    - 다양한 프로그래밍 언어를 지원하여 Spark 프로그램 내에서 모든것을 구현 가능
    - 2016년에 릴리즈된 Spark 2.0 Dataframes API가 추가되어 SQL을 쉽게 실행 가능
    - 중간 과정 확인하여 처리 가능 작은 모듈로 나누어 다양한 처리가 가능함

---

## CH 2-2 데이터

- 데이터의 종류
  - 업무 데이터
    - 서비스와 시스템을 운용하기위한 목적으로 구축된 데이터베이스에 존재하는 데이터
    - **갱신형 데이터**라고 칭함
      - 트랜잭션 데이터
        - 구매 데이터, 리뷰 데이터, 게임 플레이 데이터처럼 사용자의 행동을 기록한 데이터
        - 트랜잭션 데이터를 사용하여 리포트를 만드는 경우가 많음
      - 마스터 데이터
        - 카테고리 마스터, 상품 마스터처럼 정의하고 있는 데이터를 마스터 데이터
        - 트랜잭션의 상품 ID와 마스터 테이블을 결합해서 리포트 업무에 활용
    - 특징
      - 데이터의 정밀도가 높음 - 트랜잭션과 롤백 기능을 통한 문제 제거
      - 갱신형 데이터 - 추출하는 시점에 따라 데이터가 변경될 수 있음
      - 테이블 수가 많음 - 정규화 때문에 테이블이 나누어져 있어 이를 파악 해야 데이터의 전체 내용을 파악할 수 있음
    - 축적 방법
      - 모든 데이터 변경하기
        - 데이터 전체를 한꺼번에 바꾸어 최신상태로 만듬
        - 과거의 정보를 완전히 잃어버려 주의를 요함
      - 모든 레코드의 스냅샷을 날짜별로 저장하기
      - 어제와의 변경 사항만 누적하기
    - 업무 데이터 다루기
      - 매출액 사용자 수처럼 정확한 값을 요구할 경우 활용하기
        - 정합성이 보장된 데이터
      - 방문 횟수, 페이지뷰, 사용자 유도등에 데이터 분석에는 사용할 수 없음
      - 데이터 변경이 발생할 수 있으므로 추출 시점에 따라 결과가 변화할 수 있음
  - 로그 데이터
    - 통계 또는 분석을 주 용도로 설계된 데이터
    - 특정 태그를 포함해서 전송된 데이터
    - 특정 행동을 서버측에 출력한 데이터
    - **누적형 데이터**라고 칭함
      - 기존에 데이터를 수정하지 않음
    - 특징
      - 시간, 사용자, 엔드 포인트, IP, URL. 쿠키 등의 정보 저장하기(서비스 처리에 영향이 없음)
      - 로그 데이터는 추출 방법에 따라 데이터의 정밀도가 달라짐
      - 계속 기록을 추가하는 것뿐이므로 데이터의 변경은 없음
    - 축적 방법
      - 비컨형태(태그, SDK를 통해 사용자 장치에서 데이터를 전송하고 출력하기)
        - HTML에 특정 태그를 넣어 데이터 전송하는 형식(구글 애널리틱스)
        - 자바스크립트를 해석할 수 없는 크롤러나 브라우저의 데이터는 출력되지 않음
      - 서버형태(서버에서 데이터를 추출하고 출력하기)
        - 서버에 요청이 있을 때 출력
        - 크롤러의 접근도 출력 됨
        - 의도하지 않은 로그는 제거해야함
      - 로그 데이터 다루기
        - 방문 횟수, 페이지뷰, 사용자 유도등에 데이터 분석에 주로 사용
        - 최신 상태 고려한 분석에는 적합하지 않음
        - 누적하는 형태여서 추출 결과가 변할 가능성이 적음
        - 데이터 정확도가 업우 데이터에 비해 낮음
- 두 데이터를 사용해서 생성되는 가치
  - 업무데이터
    - 매출액의 추이, 상품의 인기 원인 파악
  - 로그 데이터
    - 원하는 리포트를 자유롭게 정의
  - 두 데이터를 활용한 새로운 가치
    - 웹사이트에서의 행동이 오프라인의 행동에 어떠한 영향을 끼치는지 등의 조사 가능
    - ex) 웹사이트에서 많이 본 상품이 실제 매장에서도 많이 팔리는 경향
  - 데이터 사용 가치
    - 목표관리: 목표를 관리하고 설계하고 조직의 성장에 기여하기
    - 서비스 개선: 사용자 행동을 기반으로 경향을 발견하고, 매출과 서비스 개선이 기여하기
    - 미래 예측: 과거의 경향을 기반으로 미래의 행동 예측하기
  - 예시로, 뽑기확률 같은걸 빅데이터로 분석하여 사용자들의 이탈을 방지할 수 있음.
