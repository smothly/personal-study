# 플랫폼으로 데이터 가져오기

## 4.1 데이터 베이스, 파일, API, 스트림 

---

- 다양한 유형의 데이터 소스
- 각 데이터 소스 마다의 특징 있음

### RDBMS

- 테이블 형태로 구조화 되었으며, 컬럼을 가짐
- 명확환 데이터 타입을 가집
- 주요 고려 사항
  - 데이터 타입 매핑: timestamp 같은 타입은 DB <-> DW 간 매핑이 쉽지 않음
  - 자동화: 수백개의 테이블을 동일한 수집 설정으로 가져올 수 있어야 함
  - 변동성: 데이터의 변화를 처리할 수 있어야 함. 특정 시점의 데이터를 가져올 수 있어야 함

### 파일

- 텍스트나 바이너리 파일을 FTP 통해 클라우드 스토리지에 저장
- 파일 포맷 다양 (csv, json, xml) + (avro, parquet, protobuf)  
- 데이터 구조가 일정하지 않아 데이터 변화에 탄력적이여야 하며 다양한 엣지 케이스를 처리할 수 있어야 함
- 주요 고려 사항
  - 다양한 파일 포맷 파싱
  - 스키마 변경
  - 스냅샷 데이터, 복수개의 파일: 일반적으로 특정 시점의 스냅샷 파일을 보내는 형태고, 여러 파일로 나누어 저장하는 형태임

### SaaS API

- salesforce, marketo 같은 업체들은 API를 제공
- 일반적으로는 JSON으로 응답
- 공급 업체마다 제공하는 방식이 다름. ex) 엔드포인트를 다중으로 구성하기, 데이터 범위
- 주요 고려 사항
  - SaaS마다 각자의 파이프라인을 가져가는 것이 좋음
  - 데이터 타입 정보가 대부분 없어, 데이터 타입 검증과 스키마 검증 등의 수행 로직이 포함되어야 함
  - 스냅샷 적재든 증분 적재든 표준을 각 파이프라인 마다 가져가기

### 스트림

---

- 이벤트 흐름은 현재 상태에 도달하기 전까지 발생했던 행위들의 순서
- Kafka, Kinesis, Pub/sub, event hub
- 주요 고려 사항
  - 메시지 포멧에 제약이 있어 데이터 이용 목적에 맞는 포맷으로 디코딩 될 수 있어야 함
  - 중복 데이터 처리
    - 신뢰성과 확장성을 확보하기 위해 동일한 메시지를 여러번 처리할 수 있는 상황을 고려해야 함
    - 메시지가 불변하기 때문에 동일한 메시지가 여러 번 올 수 있음
  - 대용량을 위한 확장성 설계

## 4.2 RDB에서 데이터 수집

---

- SQL과 CDC 사용
  
### SQL 인터페이스를 사용해 RDBMS에서 데이터 수집

- 요구사항
  - 다양한 종류의 RDBMS로 SQL 실행 가능할 것
  - 결과를 여러 포맷으로 생성하고 클라우드 스토리지에 저장할 수 있어야 함
  - SQL조회시 다양한 필터링 조건과 관련 파라미터 값들을 활용할 수 있어야 함
- 일반적인 프로세스
  - 1. RDBMS 기본 데이터 타입에 맞춰 저장 됨
  - 2. 수집 어플리케이션에 맞게 데이터 타입을 변경하여 저장
  - 3. 클라우드 데이터 플랫폼에 저장할 때 저장하는 포맷의 데이터타입으로 변환
  - 데이터 타입이 2번 이상 변경됨
- 테이블 전체 데이터 수집
  - 사용자의 가입 상태 변경, 구독 서비스 해지, 회원탈퇴 처럼 계속 데이터가 변경됨
  - **삭제된행을 식별하기 어렵고, 상태에 따른 변화를 알기 힘듬**
  - 적재 방법
    - **Daily Scheduling으로 `Select * from table` 하여 매일 스냅샷 데이터 적재**
    - 상태값 변화들을 정확히 알기 힘듬 => 삽입시간 컬럼 추가 => user_id 기반으로 데이터의 변경흐름 파악 가능
    - 중복 데이터 처리
      - 그에 맞추어 쿼리 작성
      - 처리 계층에서서 요구 사항에 맞는 데이터 세트를 구축할 것
        - 각 행의 마지막 버전만 저장
        - 마지막 스냅샷을 이전 스냅샷과 비교: 신규 로직 적용
        - 원시 데이터 세트 간결화: Upsert
- 아래와 같은 문제가 발생하여 **증분 수집**이 생김
  - 구현하기는 쉽지만 Source DB에 부하가 주고, 네트워크 지연도 발생
  - 저장 용량이 커지며 비용이 많이 발생

### 증분 데이터 수집

- 마지막 수집 이후 변경되거나 새로 추가된 행만 가져와 스토리지와 네트워크 용량의 이점을 가져오기
  - 어떤 것이 변경 및 신규 행인가?
  - 어떻게 추적할 수 있는가?
- `LAST_MODIFIED` timestamp 컬럼 기준으로 가져오기
  - MAX(LAST_MODIFIED)를 기억해놧다가 그 다음일
  - highest wateramrk(가장 최근의 타임스탬프 값)를 메타데이터 저장소에 활용
  - Glue에서는 자동으로 추적 가능
  - 직접 max 값을 관리하는 테이블을 메타데이터에 구축하여 활용할 수 있으나, 테이블이 많아지면 API 계층을 추가하여 조금 더 활용하기 편한 형태로 이용
- 데이터 양은 줄어드나 SQL의 근본적인 문제는 해결해주지 못함
  - 삭제된 행 추적 불가능. source에서 삭제하지 않도록 하거나 삭제된 행을 찾는 로직을 추가 설계 필요
  - 수집 주기 내에 여러번 변경된다면 추적 불가능
  - 한꺼번에 많은 데이터 양을 가져올 경우 여전히 DB에 부하

### CDC

- 행 변경 사항을 로그로 남기. redo logs, transaction logs, binary logs
- 모든 행의 변경 사항을 캡처할 수 있음. 이전 버전 상태와 현재 상태를 같이 관리
- 어플리케이션의 비용 추가와 실시간 인프라 비용 발생 가능
- 스키마 관련 변경도 지원함. but 스키마 지원 여부는 모름
- CDC사용할 경우 DW에서 해야할 작업
  - CDC JSON을 flat하게 다루기
  - CDC의 전체 항목이 아닌 반영 되야할 내용만 필터링
  - 초신 버전만 볼 수 있는 뷰 또는 프로세스가 필요
- 공급업체
  - Oracle
    - redo log + Oracle Golden Gate
    - Debezium Connector + Oracle XStream API
    - LogMiner 번들 - 100% 신뢰 불가. 롤백에 대한 지원이 없음
    - Quest Shareplex
  - MySQL
    - binlog사용
    - primary -> secondary 복제 구성
    - MySQL에서 제공하는 것은 없으나 대부분 Debezium, Nifi 처럼 플러그인으로 제공함
  - MS SQL
    - 트랜잭션 로그라는 변경과정을 변경 테이블로 저장하는 기능이 내장되어 있음
    - 테이블로 저장하기 때문에 SQL로 질의가 가능하며 상대적으로 구현하기가 편함
    - 대부분 제품들이 지원
    - CDC활용하는 테이블이 많다면 전체 부하가 갈 수 있음
  - PSQL
    - output plugin을 통해 행 변경 메시지를 디코딩하고 protobuf나 json메시지로 저장할 수 있음
    - 대부분 제품들이 지원

### 데이터 타입 변환

- 일반적으로 RDB가 DW보다 많은 데이터 타입을 지원함 ex) tinyint, bigint
  - RDB는 스토리지 사이즈와 성능 최적화 때문에 상세하게 타입을 나눔
  - DW는 스캔 최적화
- DW가 수용하지 않을 경우 수집 계층에서 변환할 필요가 있음
  - 툴이 지원되는 데이터 타입을 명시하고 PoC를 진행할 때 파악해 볼 것
  - 직접 개발하는 경우는 JDBC의 경우 데이터 타입을 제공하여 직접 매핑 해봐야 함
  

### NoSQL

- 데이터 추출 방법과 포맷에 대한 표준이 없다는 문제점
- 수집 방법
  - SaaS 사용
  - 별도의 수집 어플리 케이션 수집
  - MongoDB는 CDC활용
  - export 툴 사용 - 전체 내보내기의 한계
- MongoDB
  - Nested JSON 데이터
  - mongoexport
  - timestmap기반 증분 쿼리
  - CDC
- Cassandra
  - Key/Value + Columnar 데이터 
  - CQL 사용
  - COPY 명령어로 전체 데이터
  - 변경 로그를 저장할 수 있으나 처리하는 제품은 많지 않음

### RDBMS 또는 NoSQL 수집 파이프라인용 메타데이터 캡처

- 수집 파이프라인에서 수집해야 하는 몇 가지 중요한 통계 지표
  - 기본 정보
    - 소스 데이터 서버 이름 + 주소
    - 스키마
    - 테이블
  - 테이블 당 수집되는 행 수
    - 데이터가 Target으로 잘 흘러갔는지 확인
    - 수집되는 행의 이상패턴 감지
  - 수집시 소요되는 시간
    - SLA 타입 모니터링 가능
  - 배치 방식 수집 통계 테이블 예시
    - 서버 | ip | db 종류 | db | table | 적재 타입 | 시작 종료 시간 | 수행 시간
    - bigquery information schema생각하면 될 듯
  - CDC 통계 테이블 예시
    - window를 주어 window마다의 모니터링 테이블을 놔둘 것
    - op_type / 시작 종료 시간 / 경과 시간 / 삽입개수 / 업데이트개수 / 삭제개수


## 4.3 파일에서 데이터 수집

---

- 파일을 파싱하는 것은 수집 계층이 아니라 **처리 계층**에서 주로 진행됨
- FTP로 전송(on premise)
  - 보안된 네트워크 필요
  - 로컬 스토리지를 주로 사용
- FTP대신 클라우드 스토리지 사용
  - 탄력적임
  - 보안 전송 메커니즘
  - IAM과 같은 보안 옵션 활용
  - 데에터 엑세스 감사 기능

### 수집된 파일 추적

- 변경이 없는 데이터가 대부분이여서 추적할 필요는 없음
- 이미 수집된 파일인지 아닌지는 추적 필요
  - **수신과 처리됨 폴더를 나누어 구성**했을 때 장점
    - 추적이 쉬워짐
    - 파일 수집 재수행 쉬움
- 파일의 메타데이터(수집시간) 기반으로 증분된 데이터 수집 가능
  - RDB에 highest watermark와 비슷함
  - 소스테이블의 파일이 많아질수록 관리(재처리)하기 어려워져 아래와 같이 파티셔닝 된 구조로 저장하는 것을 추천
    - ex) /ftp/inventory/2020/05/17/sales_1
    - sync 기능을 사용해서 워터마크없이 저절로 신규파일 확인하여 올리는 식으로 변경

### 메타데이터

- 파일은 처리단계에서 행 수를 수집해야 함
- 파일이름에 유용한 정보들을 포함하는 방법
- 메타데이터 예시
  - source_name / file_type / start_end_ts / duration / file_name / full_path / file_size

## 4.4 스트림 방식의 데이터 수집

---

- kafka에 집중
- 실시간 수집
  - 과정: prodce -> 수집 어플리케이션 -> 메시지 허브 -> 수집 어플리케이션 -> storage or dw
  - kafka connect 같은 것으로 제공되는 솔루션을 사용할 것. 확장성, 로깅, 오류 처리 기능이 더 간단함
  - Firehose, Dataflow와 같이 DW로 적재해주는 클라우드 네이티브 서비스도 있음
  - 메시지를 일괄로 처리해 대용량의 하나의 파일로 쓰는 것이 일반적인 방법. 배치 사이즈와 소요시간과의 적절한 균형이 필요


### 배치와 스트리밍 수집의 차이점

- 데이터의 흐름과 수집 처리 완료 여부는 배치에서 중요
- 메시지 사용여부는 실시간 처리에서 기본적으로 줌. ex) message offset
  - 오프셋 관리는 어플리케이션에 부담이 됨. offset 점검 주기를 늘릴 수는 있음
  - 만약 최신화된 오프셋이 아닐경우 재시작하여 중복 적재되는 문제가 발생
  - 중복처리해야하는 기능 필요. 메시지마다 고유한 식별자가 있어야 함!
- 수신 메시지의 규모
  - 처리가 빠르고 확장성이 쉬어야 함
  - 신뢰성을 높이기 위해 메시지의 복사본을 적재하고 있으므로 메시지 버스는 저장기간이 설정되어 있어야 함
    - 대부분 일주일 이내로 구성
    - 메시지 읽으면 자동 삭제하도록도 구성 가능
    - 삭제 때문에 재처리 파이프라인이 어려울 수 있어 클라우드 스토리지에 있는 데이터를 메시지로 분해하여 스트리밍 파이프라인에 넣을 수 있는 수집 방안이 필요.
    이렇게 하면 일반적인 처리와 재처리와 같은 파이프라인 사용 가능

### 스트리밍 파이프라인의 메타데이터 캡처

- 시점별 메시지 처리 수
- 스트리밍 파이프라인의 메시지 볼륨을 모니터링 하여 장애를 감지하는 사례도 있음
- 메타데이터 예시
  - source name / start_end_ts / duration / messages
  - 스트리밍 파이프라인에서 스토리지로는 특정 간격마다 export됨. 이 때 메타데이터를 기록해도 됨
  
## 4.5 SaaS어플리케이션들로부터 데이터 수집

---

- HTTP기반 Rest API
- 인증 토큰 + API Docs + 저장

### API 설계, 데이터 내보내기 표준의 부재

- 공급업체마다 엔드포인트 구성 방식이나 데이터 제공 방식이 다름

### 중천된 Json

- Redshift는 Json을 사용할 경우 추가 변환 프로세스가 필요
- 유지보수와 데이터 활용도를 보아 개발을 산정할 것. 다양한 소스를 매번 수집 어플리케이션 개발이 힘듬
- Fivetran같이 하나에서 수집할 수 있는 서비스를 고려해볼 것. 데이터 flat기능도 제공
- 메타데이터
  - SaaS 소스 이름
  - 특정 객체 이름
  - 수집 시간
  - 객체 수

## 4.6 클라우드 데이터 수집에서 네트워크 및 보안 고려 사항

---

### 클라우드 데이터 플랫폼과 타 네트워크 간 연결

- on premise 혹은 타 클라우드 여도 인터넷이 아닌 보안 연결이 필요
  - VPN 게이트웨이 사용
  - 전용선 만들기
- 글로벌 서비스(kinesis, s3)의 경우 클라우드의 인증 암호 기능 따라야 함


## 요약

---

- RDB
  - SQL
    - 전체 데이터 수집
    - 증분 데이터 수집 - timestmamp
  - CDC
- 파일
  - 처리 단계에서 파싱
  - 수집은 변화에 탄력적으로 대응 가능해야 함
- SaaS
  - 표준화가 되어있지 않아 SaaS를 보고 판단
- 스트림
  - 중복 데이터 처리
  - 확장성 고려
- 메타데이터
  - 서버 정보
  - 테이블 정보
  - 수집 행 수(배치) or 윈도우간 처리된 메시지 수(스트리밍)
  - 수집 기간