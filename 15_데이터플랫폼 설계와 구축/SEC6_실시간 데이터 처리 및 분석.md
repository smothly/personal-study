# 실시간 데이터 처리 및 분석

## 실시간 수집 계층과 실시간 처리 계층 비교

---

- 정의
  - 실시간 수집: 소스에서 스토리지나 DW로 한번에 한 메시지를 스트리밍하는 파이프라인
  - 실시간 처리: 스트리밍 데이터를 바로 변환하는 작업을 표현할 때. 간단한 필드 변경도 포함되고, 복작한 데이터 정제도 포함
  - 실시간 데이터 분석: 스트리밍 데이터로 복잡한 계산을 할 때 ex) 특정 이벤트가 발생할 확률
- 유스 케이스
  - 대시보드를 통한 실시간 조회 
    - 실시간 수집만 필요
    - 요구사항에 따라 실시간의 정의는 달라질 수 있음
    - 리포트는 그렇지만, 데이터는 항상 실시간으로 적재되어야 함
  - 행동 패턴이 바뀔 때마다 반응하는 게임
    - 수집과 더불어 처리까지 필요
    - 분석결과를 기반으로 다른 시스템으로 보내줘야 함

## 실시간 데이터 처리 유스 케이스

---

### 실시간 수집: 일반적인 판매

- 데이터의 수집 시간이 다르기 때문에 일관성이 없어짐
  - 오프라인은 PoS로 하루에 한 번
  - 온라인은 거래 발생시마다 수집
- PoS를 실시간 수집 으로 변경하면서 해결


### 실시간 수집과 처리: 온라인 게임

- 실시간 수집은 유사하나 DW에서 실시간 분석을 하는 것에 최적화가 되어 있지 않음
- ![실시간 수집 및 처리](https://drek4537l1klr.cloudfront.net/zburivsky/Figures/CH06_F06_Zburivsky.png)
  - 실시간 처리에서 복잡한 로직을 적용하여 NoSQL, RDBMS에 저장
- DW에서 처리와의 차이점
  - DW는 수신되어야 하고 대체적으로 많은 양의 데이터를 읽어야 함
  - 데이터 서비스를 위한 엔드포인트를 만들지 않아도 됨. 즉, 데이터 엑세스가 줄어들어 Low Latency를 가지게 됨

### 실시간 수집과 처리의 비교 요약

-  실시간 수집은 분석 결과
-  실시간 데이터 처리는 DW를 활용하기엔 지연시간 이슈가 있음
-  실시간 데이터 처리는 아래와 같은 trade-off를 잘 계산하고 도입할 것
   - 추가 인프라들(저장소, 데이터처리)이 필요
   - 모니터링 및 지속적인 유지보수 필요

## 실시간 수집과 실시간 처리의 활용 시점

---

- 실시간 데이터 수집의 장점
  - 데이터가 항상 최신 상태임을 보장
  - 데이터 오케스트레이션 작업을 줄일 수 있음
  - CDC일 경우 변경 사항이 누락되지 않음
- 배치처리와 실시간처리를 한꺼번에 처리하는 업계 표준은 없음
  - dataflow는 gcp에서만 동작
  - spark는 스파크 스트리밍을 지원하나, 마이크로 배치여서 최적의 지연시간을 지원하지는 않음
- 실제로는 실시간 수집만으로 해결되는 문제가 많음. 그러므로, 데이터 소비자의 니즈가 무엇인지 정확히 파악해야 함
- 처리가 필요한 경우는 FDS, 추천엔진이 주 사용 예시
  - 처리 방식을 실시간으로 바꾸는 건 수집보다 어려움
  - **재작업 리스크를 줄이기 위해 실시간 유스케이스에 대한 계획 수립과 시스템 설계 방안에 수립**하는데 투자하는 것을 추천

## 6.4 실시간 사용을 위한 데이터 구조화

---

### 고속 스토리지의 구조

- Kafka는 실시간 데이터 수집과 처리에가장 많이 사용하는 오픈소스
- 메시지 단위로 데이터 전송되며 메시지는 topic(폴더)으로 구성됨
- 여러개의 컨슈머가 접근할 수 있는 구조
  - consumer의 경우 consume + produce(새로운 토픽으로 저장) 두가지 역할을 하는 경우도 있음
    - 공통 데이터 변환 수행 후 처리된 결과 메시지를 다른 토픽에 저장
  - 원시데이터를 바로 활용하는 consumer가 있을 수도 있음
- offset/ack 메커니즘은 신뢰성을 제공하는 데 사용
  - offset을 활용해서 재처리 가능
  - lag을 통해서 컨슈머 모니터링 가능
- 실시간 데이터는 안정성 및 메시지 추적할 수 있고, 빠른 성능 뿐만 아니라 다양한 기능을 제공하고 있어 단순히 디스크에 데이터를 저장하는 것보다 더 많은 것을 수행 가능

### 고속 스토리지 스케일링 방법

- 확장성과 가용성을 위해 시스템 클러스터를 구성하고 분산해서 실행하도록 만들어야 함
- ![카프카 구조](https://drek4537l1klr.cloudfront.net/zburivsky/Figures/CH06_F10_Zburivsky.png)
- 소비자는 추상화된 데이터를 사용해서 상관이 없지만, 장애 대응할 때는 위 분산 파티션 구조에 대해 이해가 필요

### 실시간 스토리지에서 데이터 구조화

- 배치와 흐름은 거의 똑같음
- ![실시간 데이터 구조화](https://drek4537l1klr.cloudfront.net/zburivsky/Figures/CH06_F11_Zburivsky.png)
  - 비즈니스 로직 점검 등을 위해 프로덕션 스토리지에서 pass-through로 바로 DW에 넣는 작업을 할 수도 있음
  - 짧은 지연 시간을 위한 고속 저장소 활용
  - 데이터 흐름의 각 단계별 실패 처리방안이 각각 있어야 함
- 배치의 명명규칙처럼 실시간도 필요함
  - 메타데이터에 대한 정보를 토픽정보나 메시지에서 유추 해야함
  - 소스별로 토픽을 구성하는 것이 맞을까?
    - 이슈는 없으나 메시지 구조 자체를 먼저 식별하고 각 토픽마다 변환작업이 들어감
    - 공통 데이터 변환 작업이 좋음
    - 토픽 하나만 사용해도 메시지 속성을 잘 활용하면 공통으로 데이터 변환처리가 가능
      - ![CDC예시](https://drek4537l1klr.cloudfront.net/zburivsky/Figures/CH06_F13_Zburivsky.png)
    - 실시간 처리 작업, 토픽 수를 줄일 수 있고 솔루션을 더욱 쉽게 모니터링할 수 있음
    - 공통된 메시지 포맷이 아니라면 ex) 3rd party 토픽을 별도로 구성하는 것이 나음
    - 또는, 한도에 다다를 때 변경해야 함
- 여러토픽으로 분할하는 경우
  - 재무 데이터나 HR데이터의 경우 공통 라우팅 작업을 통해 별도 토픽으로 분리해서 접근 제어해야 함
  - ![예시](https://drek4537l1klr.cloudfront.net/zburivsky/Figures/CH06_F14_Zburivsky.png)
  - 데이터 품질 체크 기반으로 실패, 스테이징 분기 처리

## 6.5 실시간 시스템에서 공통 데이터 변환

### 실시간 시스템에서 데이터 중복의 원인

- 배치의 경우 컬럼 기준으로 중복을 판단 했음
- 실시간 중복의 경우
  - 종류
    - 소스에서 발생한 중복 데이터
    - 실시간 장애복구중에 발생하는 중복 데이터
  - 데이터 플랫폼 외부에서의 중복은 통제할 수 없음
  - porducer쪽에서 ack을 못받는 경우 메시지를 2번 보내여 중복 발생
  - consumer쪽도 동일하게 ack을 못받으면 메시지 중복 처리

### 실시간 시스템에서 데이터 중복 제거

- 실시간 시스템은 스냅샷 처럼 한 번에 모든 데이터를 보는 기능은 없음
- 중복 제거 옵션
  - time window or event timestamp
    - 특정 윈도우간의 중복처리는 가능. but 캐싱하여 사용하는 것이여서 성능에 제약이 잇음 kinesis는 1시간
  - Unique ID를 고속 데이터 스토리지에 캐싱
    - NoSQL같은 매우 빠른 스토리지
    - ms단위의 지연시간과오버헤드가 되면 안됨
    - 16byte UUID의 경우 10억개 저장 가능 최대 15GB스토리지 사용하여 스토리지 자체는 성능이 별로 필요하지 않음. but, 스토리지 관리 필요
    - 스트로지가 중지되면 전체 실시간 데이터 파이프라인이 중지됨
  - DW를 활용한 중복 제거
    - 우선 실시간으로 적재하고 배치방식으로 제거
    - 스트림 영역이 아니라 처리영역에서 제거되는 것임. 서버 리소스가 많이 필요할 수 있음
    - DW에 전송이 우선일 경우 주로 사용

### 실시간 파이프 라인에서 메시지 포맷 변환

- JSON을 주로 사용
- 배치와 똑같이 avro 같은 binary format사용하여 저장
- 스키마 자체를 저장할 메타데이터가 있어야 함. 이를 통해서 인코딩/디코딩이 가능
- parquet은 여러 컬럼을 스캔해야할 때 좋은 것으로 메시지 처리의 경우에는 도움이 되지않음

### 실시간 데이터 품질 체크

- 메시지마다 규칙을 적용하는 것은 쉽지 않음. 규칙을 적용하여 실패 토픽, 스테이지 토픽등으로 분리할 수 있음 ex) 음수인 가격
- Window를 기반으로 체크 ex) 1시간동안 발생한 메시지 중 취소가 10% 이상이면 문제
- window의 한계를 넘어서면 처리 계층에사 작업. (중복제거와 똑같음)

### 배치 데이터와 실시간 데이터 결합하기

- 배치 데이터를 메모리에 캐싱하여 딕셔너리처럼 참조할 수 있도록 함
- 실시간 데이터 수집일 때 결합이 필수적인 상황에서 쓰는 방법으로, DW에서 뷰를 제공하거나 조인작업을 진행하여도 됨

## 6.6 실시간 데이터 처리용 클라우드 서비스의 종류

- 실시간 스토리지와 실시간 처리 구분

||real time storage|real time analytics|
|---|---|---|
|AWS|Kinesis Data Streams|Kinesis Data Analytics|
|GCP|Pub/Sub|Dataflow stream analytics|
|Azure|Event hubs|Stream Analytics|
    
### AWS 실시간 처리 서비스

- KDS
  - 데이터 스트림은 카프카의 토픽과 유사
  - Consumer는 Kinesis Client Library 를 사용해서 구현 가능
  - 레코드 순차번호 추적이나 DynamoDB캐싱 등을 통해 단순화 시켜줌
  - Firehose로 데이터 스트림의 데이터를 읽어 다수의 데스티네이션과 싱크할 수 있음
  - 샤드(파티션) 정의 해야함 1mb/sec 쓰기와 2mb/sec 읽기 지원
  - 샤드 확장 축소도 지원
  - 메시지 크기는 1MB
  - 24시간 저장 최대 7일
- KDA
  - SQL과 JAVA API제공
  - Flink를 통해 유연하게 처리도 가능

### GCP 실시간 처리 서비스

- 상대적으로 고수준의 서비스. 관리할 포인트가 없음
- pub/sub
  - 토픽은 메시지를 그룹화하는 서비스이나 카프카의 토픽보다는 중요도가 덜함
  - 파티션 관점으로 고려할 필요가 없음
  - 컨슈머가 토픽을 구독하는 형태
    - 하나의 구독은 1mb/sec 쓰기와 2mb/sec 읽기 지원함
    - 메시지 크기 최대 10MB, 최대 7일 보존
  - 오프셋 개념이 없어 구독의 스냅샷을 만들 수도 있음
- dataflow
  - beam api를 기반으로 하는 완전 관리형 서비스
  - **배치 + 실시간을 같이 지원**
  - SQL(json 포맷만 지원), Java, Python 지원해서 간단한 파이프라인 
  - 구글 서비스와 통합 가능
  - 중복 메시지가 10분이내 있는 경우는 자동으로 처리 가능

### Azure 실시간 처리 서비스

- event hub
  - producer를 위한 다양한 프로토콜 지원. AMQP, HTTPS,Kafka. 이식성이 좋다는 뜻
  - 오프셋 저장은 blob storage를 지원하나 고속으로 필요할 경우 별도로 연결해야 함
  - 나머지 제약 조건은 Kinesis와 대부분 비슷
  - event hubs capture로 firehose와 유사하게 저장은 가능하지만 azure blob storage만 지원하고 잇음
- azure stream analytics
  - sql구문만 지원
  - 대신 sql확장기능을 지원 ex) windowing, winodw joi
  - 데이터 export 가능
  - databricks의 spark streaming API를 활용하여 세분화된 분석 처리도 가능
  - 데이터 중복제거는 synapse에서 진행

## 요약

- 처리 계층은 비즈니스 로직 적용, 데이터 검증, 변환 작업
- 실시간 수집과 처리의 정의
- 요구사항을 명확히 파악할 것. 대부분 수집만으로 처리가 됨
- 배치 시스템은 파일 단위로 처리. 실시간은 메시지 단위로 처리.
- 다중 분산 클러스터로 가용성 확장성 보장
- 중복 문제는 항상 발생하고 해결은 가능하나 성능상 비용상 문제들이 발생
- avro 포맷으로 공통 형식 사용하면 스키마 없이 메시지를 보낼 수 있고, 용량도 작음
- 실시간 서비스 다양