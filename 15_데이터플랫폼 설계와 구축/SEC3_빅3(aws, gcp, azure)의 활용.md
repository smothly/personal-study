# 빅 3(aws, gcp, azure)의 활용과 확대

- 데이터 플랫폼에서 필요로 하는 핵심 기능과 고급 기능
  - 확장성
  - 3V 대응

## 3.1 클라우드 데이터 플랫폼 레이어 아키텍처

---

- 수집, 저장, 처리, 서비스 4개 레이어에서 **메타데이터 레이어과 오버레이 레이어**가 추가됨
- ![6계층](https://edwardthienhoang.files.wordpress.com/2023/02/image-9.png)

### Ingestion Layer

- 소스 시스템에 연결해 데이터를 가져오는 역할
- 스트리밍, 배치 두가지 모드로 가져옴
  - 실시간의 의미
    - 데이터가 수집되자마자 분석이 가능한 형태로 만들기 = 실시간 수집
    - 데이터가 수집되는 즉시 분석하여 조치 ex) 부정행위, 추천시스템
    - 아직 실시간 분석이 많이 필요없으나 보고서 대시보드의 시점을 최신 상태로 유지 가능하여 요구사항에 따라 구축
- **소스와 같은 원시 데이터를 보관**해야 함. 그래야 재처리할 때도 소스의 연결 필요없이 처리 가능
- 메타데이터 저장소에서 수집 통계, 상태를 알 수 있어야 함. ex) 시간당 데이터 수집량
- 어떤 수집이든 일급 객체로 구축해야 견고한 아키텍처가 됨
  - 일급객체
    - 다른 객체들에 적용 가능한 연산을 모두 지원하는 객체. 함시 인자로 넘기기 변수 대입 등을 지원
    - 클라우드에서 이 개념을 적용하면 **제약 없는 리소스**
- 람다 아키텍처
  - 실시간 분석 + 정확한 분석을 위해서 배치와 스트리밍을 모두 지원해야 함
  - 처음 나오게 된 배경은 하둡초기인데 회복성과 정확성을 보장하기 어려웠기 떄문임. 현재 클라우드 서비스에서는 많이 극복함
- 효율적이고 안정적인 수집 특성
  - Pluggeable architecture: 큰 노력없이 새 커넥터 유형 추가
  - Scalability(확장성): 대량의 데이터 처리 가능
  - High Availability(고가용성): 장애 대응 체계가 있어야 함
  - Observability(관측 가능성): 데이터 이동에 대한 가시성. 처리량, 지연 시간 등

###  고속 스토리지와 저속 스토리지

- 고속 스토리지
  - 스트림 방식 데이터를 메시지 단위로 데이터 처리하기 위한 메시지 버스
    - 컴퓨팅 서버가 필요하고 비용도 비쌈
  - persistence queue
  - 실시간 속성
- 저속 스토리지
  - 배치 데이터 저장 영역. 영구 보관
  - 객체 스토리지
    - 장점: 컴퓨팅 서버가 없어 확장성이 좋고 비용 효율적
    - 단점: low-latency를 지원하지 않음. 이를 위해 고속스토리지(큐)를 활용해야 함
- 스토리지가 가져야 할 특성
  - Reliable(안정성): 데이터 지속 유지
  - Scalable(확장 가능성)
  - Performant(성능): 배치는 읽기 성능 실시간은 Low-Latency
  - Cost Efficient(비용 효율성)

### 처리 계층

- 비즈니스 로직 적용, 데이터 검증, 데이터 변환이 수행 되며 ad-hoc 접근 가능
- 데이터 소비자들이 데이터를 스토리지에 다시 저장할 수 있어야 함
- 다른 시스템에도 데이터를 제공할 수 있어야 함
- apache beam은 배치와 실시간을 동시에 처리할 수 있음
- 처리 계층이 가져야 할 특성
  - 스케일 아웃: PB까지 처리가능해야 함
  - 배치와 실시간 처리 둘다 지원해야 함
  - 프로그래밍 언어 지원
  - SQL인터페이스는 있으면 좋은 조건. 생산성 향상

### 기술 메타데이터 계층

- 데이터 플랫폼 계층들의 처리상태에 대한 정보를 저장함
  - 스키마 정보
  - 수집 상태 정보
  - 파이프라인 상태+계보 정보
  - 데이터 통계 정보
- 각 계층에서 저장소의 메타데이터를 읽고, 추가 변경할 수 있도록 인터페이스 제공
- 메타데이터 계층이 가져야 할 특성
  - Scalable(확장성)
  - HA: 모든 처리 계층이 바라봐야해서 SPOF가 될 가능성이 높음
  - Extendable(확장 가능): 메타데이터 종류가 정확히 정해져 있지 않아, 확장 가능한 형태로 되어야 함
- 모든 요구사항을 만족하는 솔루션은 없음 ex) confluent schema registry, glue

### 서비스 계층과 데이터 소비자

- 관계형 데이터 구조와 SQL지원을 원하는 데이터 소비자는 DW를 활용하기 희망함
  - DW의 역할은 사용자가 요청하는 **쿼리결과를 신속하게 제공하는 것**이 그 역할
- 특성
  - Scalable and reliable
  - no ops: 운영 포인트가 최대한 적어야 함
  - elastic cost model: 사용량에 따른 분석비용 청구 ex) 평일 9시에 집중됨
- DL 접근은 DS분들이 많이 사용
  - 원시 데이터와 많은 양의 데이터 접근
  - DW의 부하를 주지않기 위함
- **실시간 분석 파이프라인의 경우 대부분 애플리케이션이 소비자**임

### 오케스트레이션 오버레이와 ETL 오버레이 계층

- 다양한 툴로 분산되어 있음
- orchestration layer = workflow
  - dependency graph를 기반으로 여러 데이터 처리 작업을 조정할 수 있어야 함
  - 작업 실패와 재시도 관리
  - 느슨하게 결합된 각 계층간의 흐름을 구성하는 역할
  - 가져야 할 특성
    - Scalability
    - HA
    - Maintainability(유지보수성)
    - Transparency(투명성): 모니터링에대한 가시성이 제공되어야 함
  - ex) airflow, gcp cloud composer, oozie
- etl tool overlay
  - 데이터 파이프라인을 더욱 쉽게 구현하고 관리하도록 하는 제품
  - UI나 No code방식의 개발이 가능
  - 역할
    - 데이터 수집
    - 파이프라인
    - 메타데이터
    - 오케스트레이션
  - 그러면 단일 툴로 가능한가?
    - 경우에 따라 그럴 수 있다
    - 확장 가능한지, 신규 컴포넌트 추가 가능한지, 외부 데이터 처리 가능한지, 오픈소스와 통합가능한지
    - 초기에는 좋을 수 있으나, 어떤 시스템도 정적이지가 않음
  - 가져야 할 특성
    - Extensibility: 컴포넌트 쉽게 추가
    - Integrations: 일부 작업은 다른 데서 가능한지
    - Automation maturity: GUI가 초반 접근은 되지만, CI/CD와 자동화 테스트 등 유지보수가 편한 형태가 되는지
    - Cloud Architecuture fit: 대부분 on premise형태, 
  - glue, data factory, cloud data fusion

## 3.2 데이터 플랫폼 아키텍처에서 계층의 중요성

---

- **각 계층의 역할을 정의하고 역할간 느슨한 결합형태로 아키텍처를 구성해야 유연성이 극대화** 된다.
- 스파크는 처리와 수집에 모두 활용할 수 있으나, 최선의 결정은 아님. 아래 사항들을 고려해야 힘
  - 최상의 데이터 수집 + 처리인가?  스파크 커넥터가 확장성이 좋은가?
  - 데이터 변환과 처리 부분은 셀프로 수집은 중앙 집중화되어 운영되는게 보통인데, 데이터 처리가 셀프 서비스처럼 유지되는가?
  - 데이터 처리를 변경하게 된다면 수집은 기존 방식대로 진행 가능한가?

## 3.3 클라우드 데이터 플랫폼 계층에 활용할 수 있는 툴 매핑

---

- 각 계층을 클라우드 환경의 서비스와 매핑할 예정
- OpenSource <-> Serverless <-> SaaS, PaaS
  - 좌측일수록 유연성 낮음, 관리 포인트 높음, 이식성 좋음
  - 결국 선택할 때 `관리포인트 vs 오픈소스 이점(이식성, 커스터마이징)`을 비교해야 함
  - PaaS의 기능이나 오픈소스의 기능이 필요하지 않는 상황이라면 SaaS 솔루션을 써도 됨. 또는 기존의 투자를 보호할 때

### AWS

- ![aws cloud data platform](https://edwardthienhoang.files.wordpress.com/2023/02/image-21.png)
- 배치 데이터 수집
  - Glue
    - S3 데이터 수집과 JDBC를 활용해 가져올 수 있음
    - 외부 API나 DynamoDB는 지원하지 않음
  - AWS DMS
    - 대부분 RDB지원
    - S3를 타겟으로 활용할 수 있음
    - CDC 지원
  - **CDC요구사항이 없다면 Glue로 통일하는 것을 추천**
  - 지원되지 않는 것은 직접 구현해야 함
- 스트리밍 데이터 수집
  - Kinesis
    - 메시지 버스 역할
    - 데이터 생산은 직접 작성해야함
    - 커넥터는 제공하지만 AWS관련 데이터 소스들만 해당됨
    - Firehose
      - Kinesis에서 데이터를 읽고 변환하는 기능을 내장한 서비스
      - Json을 읽어 Parquet저장 같은 일을 함
  - Glue Streaming
    - 스트리밍 데이터 처리 역할
    - Spark Streaming과 동일
    - Kinesis, Kafka로 부터 데이터 수집 처리 가능
  - MSK
    - Fully Managed Kafka
    - 카프카 기반의 아키텍처에서 유용
- 데이터 플랫폼 스토리지
  - S3
  - 티어 기능을 잘 활용할 것
- 배치 데이터 처리
  - EMR
    - 기존 MR작업도 사용 가능
    - HDFS, S3 둘 다 처리 가능
    - 사용할 때만 가용하는 식으로 탄력적 운영 가능
- 실시간 데이터 처리 및 분석
  - 실시간 데이터 분석이란 메시지를 한 번에 하나씩 처리
  - KDA 사용: SQL 지원
  - MSK의 경우 카프카 스트림즈 사용 가능
- DW
  - MPP 아키텍처
  - S3, Kinesis와 밀접하게 연결되어 있어 RS에 쉽게 적재 가능
  - Spectrum을 사용해서 S3 외부 테이블 쿼리
    - 외부 테이블 생성 및 스키마 정의 필요
    - 대부분의 프로세싱은 DW외부에서 실행됨. 속도는 느림
- 데이터 플랫폼 직접 액세스
  - Athena
  - 쿼리 수행할 때 바로 프로비저닝함
  - 스캔당 비용
- ETL 오버레이 및 메타데이터 저장소
  - Glue
    - 데이터 수집 + 처리가 가능함(Spark와 유사)
    - 유연한 스키마 지원을 활용해 증분 데이터 적재를 위해 데이터 종류 추적 가능
    - 반정형 -> 정형으로 변환하는 템플릿 제공하여 RS 적재 용이
    - 코드의 이식성은 낮음
  - 데이터 카탈로그
    - S3에 있는 모든 데이터에 대한 스키마 정보 존재
    - 카탈로그를 최신  상태로 유지
    - 파이프라인의 통계지표를 유지 관리함
- 오케스트레이션 계층
  - Glue 스케줄링은 Glue 위에서 구축된 것만 가능
  - 다른 서비스들은 Step function으로 가능
  - 데이터 파이프라인
    - 데이터 전송 스케줄링하고 실행하는데 초점이 맞춰져 있음
    - 더이상 확장이 없을 예정
- 데이터 소비자
  - RS나 Athena를 통한 BI 지원 
  - 웹 인터페이스로 ad-hoc분석 가능
  - 빠른 처리 성능은 DynamoDB 활용

## GCP

- ![google cloud data platform](https://edwardthienhoang.files.wordpress.com/2023/02/image-22.png)
- 배치 데이터 수집
  - Data fusion
    - etl overlay로 UI편집기를 사용해 dataproc과 dataflow와 같은 다양한 데이터 처리엔진으로 파이프라인 수행 가능
    - JDBC, FTP, S3커넥터도 있음
    - CDAP 오픈소스를 기반으로 함
  - cloud function
    - AWS Lambda와 비슷
  - bigquery data transfer service
    - 빅쿼리로 데이터를 수집
    - Google Analytics, Adwords, Youtube등 구글 관련 SaaS 데이터와 통합됨
    - Fivetran과 파트너십을 통해 데이터 수집이 더 다양화 됨
    - 단점은 Bigquery로 직접 전송된다는 점
      - 데이터 엑세스와 처리 방법에 제약이 있을 수 있음
      - 하지만 이 과정을 단순화 시키는게 더 좋을 수 있음
    - DMS와 비슷
- 스트리밍 데이터 수집
  - pub/sub
    - 메시지 버스
    - kinesis와 유사하지만 메시지 저장소와 전달 서비스만 제공함
    - 커넥터와 데이터 변환 기능은 제공하지 않고 직접 코드 작성해야 함
- 데이터 플랫폼 스토리지
  - GCS
- 배치 데이터 처리
  - Dataproc
    - EMR과 유사
    - 데이터를 GCS에서 가져와 변환 처리만 해줌
  - Dataflow
    - Beam의 완전 관리형 실행 환경 서비스
    - 분산 데이터 처리를 위한 오픈 소스 프레임 워크
    - **배치와 실시간 둘다 동일한 프로그래밍 모델을 활용**
- 실시간 데이터 처리오 ㅏ분석
  - dataflow + beam + pub/sub
    - beam은 윈도우, 트리거, 지연메시지 처리 등 실시간 처리 기능들 제공
    - data flow는 java, python, beam작업 지원. SQL도 개발중
  - dataproc
    - Spark streaming 활용
    - 스파크에 익숙한 조직이 활용하고 웬만하면 beam을 사용하는 것이 좋음
- DW
  - Bigquery
  - 분산DW
  - 자동화된**컴퓨팅 관리**
  - 스캔비용당 청구고 데이터 비용 예측 추정 어려움
  - 반정형 데이터 지원 함수 많음
- 데이터 플랫폼에 직접 엑세스
  - 전용 서비스 없음
  - 빅쿼리 외부 테이블 기능 사용 + 임시 외부 테이블 사용 가능
    - 스키마 제공해야하는 점이 단점
  - 임시 dataproc을 구축하여 SparkSQL방법도 있
- ETL 오버레이와 메타데이터 저장소
  - Data Fusion
    - 관리형 ETL 서비스
    - UI로 데이터 처리 및 분석 프이프라인까지 변환 가능
    - 다 만들면 data proc으로 변환 가능
    - 파이프라인 관리가 한곳에서 됨
    - 모니터링 지표 제공
- 오케스트레이션 계층
  - cloud composer 
    - Airflow의 Fully Managed Service
    - 더욱 쉽게 관리할 수 있음
- 데이터 소비자
  - 빅쿼리는 REST API를 통해 동작함
  - 심바의 JDBC/ODBC 드라이버는 브릿지역할 제공하는 것이여서 한계점이 있음
  - 대부분의 BI툴에서 Bigquery 커넥터 지원

## Azure

- ![azure cloud data platform](https://edwardthienhoang.files.wordpress.com/2023/02/image-20.png)
- 배치 데이터 수집
  - Data Factory
    - Batch Ingestion 지원
      - FTP, Storage Service, NoSQL, Saas 등 **가장 많은 양의 커넥터 지원**
    - Azure 제품과 통합되어 있음
    - HTTP 커넥터로 확장도 가능하여 REST API형태도 수집 가능
  - Azure Function
- 스트리밍 데이터 수집
  - Azure Event Hubs
    - 메시지 허브
    - Kafka API와 호환됨
    - Event hub capture를 통해 blob storage나 synapse로 저장할 수 있음
- 데이터 플랫폼 스토리지
  - s3와 유사
  - data lake storage 서비스 출시해서 대규모 데이터 처리 가능
- 배치 데이터 처리
  - Databricks와 연계됨. 자체 서비스는 없음
- 실시간 데이터 처리 및 분석
  - Azure Stream Analytics
    - 스트리밍 데이터 처리및 변환 제공
    - SQL과 유사한 언어도 지원
    - 다양한 Azure 서비스를 Destination으로 활용 가능
    - Kafka와도 호환
- DW
  - 스토리지와 컴퓨팅이 분리된 구조
  - 컴퓨팅 리소스 확장 축소 쉬워서 탄력성 있는 운영 가능. Redshift와 Bigquery의 중간
- 데이터 플랫폼에 직접 액세스
  - Databricks 활용하기
    - Spark 기능 전부 활용 가능
    - Azure 서비스들과도 통합 가능
- ETL 오버레이 및 메타데이터 저장소
  - Datafactory
    - 파이프라인의 구성, 실행, 모니터링할 수 있는 UI 제공
    - API지원으로 CI/CD 구축 가능
    - 다양한 변환은 미제공하며 databricks hook사용하면 커스텀한 변환 가능
    - 모니터링 지표 다양. 스키마 변경과 데이터 볼륨 변경은 캡처할 수 없음
  - Data Catalog
    - 데이터 검색기능의 초점을 맞춴 DDP
    - SQL엑세스를 지원하면 기본 데이터 프로파일링 지원
- 오케스트레이션
  - Data Factory는 복잡한 파이프라인 간의 의존성관리 기능
- 데이터 소비자
  - Synapse가 대부분 BI나 SQL지원
  - Databricks로 커넥터 지원이 되지만 비용이 많이 듬
  - cosmos DB(Document)로 빠른 액세스 지원 가능

## 3.4 상용 소프트웨어 및 오픈 소스 대안

---

- 클라우드가 적합하지 않는 경우도 있음
  - 기능관점 제한 Functionality Limitations: 서비스가 필요한 기능을 모두 갖추고 있지 않음
  - 비용: 데이터 볼륨에 따라서는 비합리적인 비용이 들 수 있음
  - 이식성 Portability: Cloud의 종속성을 줄이기 위함

### 배치 데이터 수집

- Nifi
  - 데이터 수집 오픈소스
  - 커넥터 라이브러리를 지원
  - Java로 커넥터 생성 가능
- Talend
  - 오픈 코어 모델
  - 전체 파이프라인 담당
- Fivetran, Alooma
  - 데이터 수집만 전문적으로 하는 3rd Party SaaS
  - 다양한 커넥터, 모니터링, 간단한 변환 제공
  - 보안적인 문제와 DW적재에 특화되어 있어 유연한 데이터 아키텍처가 되기엔 어려움

### 스트리밍 데이터 수집 및 실시간 분석

- Kafka
  - Connect Component 지원
  - 처리 기능인 Kafka Streams도 지원
  - 풍부한 기능셋, 성능, 전문성 때문에 선택하고 클러스터 관리의 단점이 있음
  
### 오케스트레이션 계층

- Airflow
  - 작업 의존성 관리, 로깅, 알람, 재시도 메커니즘
  - 파이썬 프로그래밍으로 작업 정의 가능
  - 외부 구성정보나 파라미터 설정 가능


## 요약

---

- 6계층(수집, 처리, 저장, 메타데이터, 서비스, 오케스트레이션+ETL Overlay)으로 구성됨
- 느슨하게 결합된 계층!
- 수집은 Plug형 아키텍처, 확장성, 고가용성, 관찰성
- 스토리지는 장기와 단기 데이터 저장. 안정성, 확장성, 성능, 비용 효율성
- 처리는 다양한 유형의 비즈니스 로직과 대화형 방식 모두 지원
- 데이터 플랫폼에 직접 엑세스할 수 있는 방법도 설계(분산 SQL엔진, 데이터 처리, 직접 파일 읽기)
- 메타데이터는 자동화, 모니터링, 알람으로 활용될 수 있기 때문에 파이프라인 상태나 테이블 정보들이 잘 관리해야 함. 하지만, 아직 완벽한 툴은 없음
- 데이터 소비는 SQL을 기반으로 하되 프로그래밍도 고려해야 실시간 처리가 가능해짐
- orchestration은 워크플로!
- ETL Overlay Tool은 데이터 파이프라인은 보다 쉽게 구현하고 유지 관리. 다양한 계층에 걸쳐 있음
- 여러 툴들을 조합해야함 PaaS를 적절히 조합하여 유지보수를 최소화할 것